{"cells":[{"cell_type":"markdown","metadata":{"id":"ZuGnM0aAS_Ly"},"source":["# SC4002 / CE4045 / CZ4045 Natural Language Processing (AY 2023-2024 Assignment)\n","## Part 1. Sequence Tagging: NER"]},{"cell_type":"markdown","metadata":{"id":"X3XC53LgS_L3"},"source":["#### 1.1 Word Embedding"]},{"cell_type":"markdown","metadata":{"id":"xZSOhGDC9E5s"},"source":["1. Word2vec could be accessed via the gensim library.\n","\n","*(Gensim is designed to process raw, unstructured digital texts (“plain text”) using unsupervised machine learning algorithms.)*\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPot0SL28144","outputId":"a54b6628-d7a1-474e-cbc5-af6975376860","executionInfo":{"status":"ok","timestamp":1699333322071,"user_tz":-480,"elapsed":5846,"user":{"displayName":"Code Till","userId":"00349487664103867259"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"]}],"source":["pip install --upgrade gensim"]},{"cell_type":"markdown","metadata":{"id":"7dio5bXM9eaY"},"source":["2. Download the pretrained word2vec embeddings following the instructions under Section Pre-\n","trained Models. Download the embeddings under this name: **word2vec-google-news-300**."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_FfWfi999Mdr","outputId":"e1e8061a-7a18-467e-d165-e8094b6b4f69","executionInfo":{"status":"ok","timestamp":1699334024911,"user_tz":-480,"elapsed":702842,"user":{"displayName":"Code Till","userId":"00349487664103867259"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n","[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"]}],"source":["import gensim.downloader\n","\n","print(list(gensim.downloader.info()['models'].keys()))\n","# Download the \"word2vec-google-news-300\" embeddings and store in w2v\n","w2v = gensim.downloader.load('word2vec-google-news-300')"]},{"cell_type":"markdown","metadata":{"id":"Fo0age7k-uwI"},"source":["3. Now you should be able to query the vector of any word by specifying the word as the key.\n","For example, if you store the pretrained embeddings under variable name w2v, you can run\n","w2v[‘computer’] to retrieve the vector for ‘computer’."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OAiuBC8G-tEK","outputId":"46a3f083-8c31-4514-ee49-11123aab6eee","executionInfo":{"status":"ok","timestamp":1699334024912,"user_tz":-480,"elapsed":37,"user":{"displayName":"Code Till","userId":"00349487664103867259"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('computers', 0.7979379892349243),\n"," ('laptop', 0.6640493273735046),\n"," ('laptop_computer', 0.6548868417739868),\n"," ('Computer', 0.647333562374115),\n"," ('com_puter', 0.6082080006599426),\n"," ('technician_Leonard_Luchko', 0.5662748217582703),\n"," ('mainframes_minicomputers', 0.5617720484733582),\n"," ('laptop_computers', 0.5585449934005737),\n"," ('PC', 0.5539618730545044),\n"," ('maker_Dell_DELL.O', 0.5519254207611084)]"]},"metadata":{},"execution_count":3}],"source":["w2v.most_similar('computer')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USZURJpNS_L-","outputId":"43f6ef26-6044-4c94-cd16-c4b2fcbb7d89","executionInfo":{"status":"ok","timestamp":1699334024912,"user_tz":-480,"elapsed":32,"user":{"displayName":"Code Till","userId":"00349487664103867259"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n","       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n","        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n","        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n","       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n","       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n","        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n","        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n","       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n","       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n","       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n","        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n","       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n","        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n","        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n","        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n","       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n","       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n","        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n","        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n","        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n","        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n","       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n","       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n","        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n","        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n","       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n","        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n","       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n","       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n","       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n","       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n","        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n","       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n","        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n","        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n","       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n","       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n","       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n","       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n","       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n","       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n","       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n","       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n","        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n","       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n","        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n","        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n","       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n","        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n","       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n","        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n","       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n","       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n","       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n","       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n","       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n","       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n","       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n","        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n","        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n","       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n","        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n","       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n","        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n","       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n","        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n","       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n","       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n","       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n","        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n","        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n","        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n","        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n","        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n","      dtype=float32)"]},"metadata":{},"execution_count":4}],"source":["w2v['computer']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ACPQKERAA3Y"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"j-GXAjNg-XGX"},"source":["**Question 1.1**\n","\n","Based on word2vec embeddings you have downloaded, use cosine similarity to find the most similar\n","word to each of these words: (a) “student”; (b) “Apple”; (c) “apple”. Report the most similar word\n","and its cosine similarity."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zoE26ds-KbE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699334024912,"user_tz":-480,"elapsed":30,"user":{"displayName":"Code Till","userId":"00349487664103867259"}},"outputId":"2571d53f-a290-4fe9-eb04-7be473b73a60"},"outputs":[{"output_type":"stream","name":"stdout","text":["Most similar word to 'student': students (Cosine Similarity: 0.73)\n","Most similar word to 'Apple': Apple_AAPL (Cosine Similarity: 0.75)\n","Most similar word to 'apple': apples (Cosine Similarity: 0.72)\n"]}],"source":["# function to find the most similar word (words that are similar to the given words)\n","#and cosine similarity (measure of similarity for 2 vectors)\n","def mostSimilarWordsFunc(word):\n","    try:\n","        similarWords = w2v.most_similar(word)\n","        mostSimilarWord, cosSimilarity = similarWords[0]\n","        return mostSimilarWord, cosSimilarity\n","    except KeyError:\n","        return \"Word not found in vocabulary\", 0.0\n","\n","# Find the most similar words for the given words\n","words = [\"student\", \"Apple\", \"apple\"]\n","\n","for word in words:\n","    mostSimilarWord, cosSimilarity = mostSimilarWordsFunc(word)\n","    print(f\"Most similar word to '{word}': {mostSimilarWord} (Cosine Similarity: {cosSimilarity:.2f})\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LrbaS11MS_L_"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bhEHYCZcS_L_"},"source":["#### 1.2 Data"]},{"cell_type":"markdown","metadata":{"id":"nbBMxiKFfzyF"},"source":["Then you can start to prepare the dataset. For NER, you will work with CoNLL2003 (click and\n","download “eng.testa”, “eng.testb”, “eng.train”). Before training, you need to preprocess the dataset\n","such that each of them contains a training file, a development file and a test file. The development\n","file is used to select the best model during training. The test file is used for final evaluation. For\n","CoNLL2003, the training, development and test file corresponds to “eng.train”, “eng.testa” and\n","“eng.testb”, respectively. Note that you only need to use the first and the last column of each\n","line corresponding to the input word and the word label, respectively. A screenshot of the data is\n","shown in Figure 1. In this example, there are two sentences (separated by ‘\\n’). The input for each\n","sentence is composed of the words from the first column. For example, the first sentence in Figure\n","1 corresponds to “*CRICKET - LEICESTERSHIRE TAKE OVER AT TOP AFTER INNINGS\n","VICTORY.*” The label for each of the first 3 words *CRICKET, -, LERCESTERSHIRE* corresponds\n","to ‘O’, ‘O’, ‘I-ORG’, respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXyWFpqm3FPa"},"outputs":[],"source":["from collections import OrderedDict\n","import re\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import init\n","from torch.autograd import Variable\n","from torch import autograd\n","import codecs\n","import pandas as pd\n","\n","\n","parameters = OrderedDict()\n","parameters['train'] = \"eng.train\"\n","parameters['dev'] = \"eng.testa\"\n","parameters['test'] = \"eng.testb\"\n","parameters['tag_scheme'] = \"BIOES\" # can be BIO or BIOES\n","parameters['setzero'] =  True\n","parameters['setlower'] = True # Boolean variable to control lowercasing of words\n","\n","#Following the Google-news-300 dimensions\n","parameters['name'] = \"G38-NLP-model\" # Model name\n","parameters['char_dim'] = 30 # Char embedding dimension\n","parameters['weights'] = \"\" # path to Pretrained for from a previous run\n","parameters['dropout'] = 0.5 # Droupout on the input\n","parameters['epoch'] =  10 # Number of epochs to run\n","parameters['gradient_clip'] = 5.0\n","parameters['char_mode'] = \"LSTM\" # default will be LSTM, can be changed to CNN\n","parameters['word_dim'] = 300 # Token embedding dimension\n","parameters['word_lstm_dim'] = 200 # Token LSTM hidden layer size\n","parameters['word_bidirect'] = True # Use a bidirectional LSTM for words\n","parameters['crf'] =1 # Use CRF (0 to disable)\n","\n","# GPU\n","parameters['use_gpu'] = torch.cuda.is_available() # GPU Check\n","use_gpu = parameters['use_gpu']\n","\n","#Constants\n","START_TAG = '<START>'\n","STOP_TAG = '<STOP>'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"opaX9qdC7OWC"},"outputs":[],"source":["# Training of the Model will be focus towards the words as all digits will be zeroes instead of the different digits\n","def replaceDigitsWithZeros(s):\n","    # Change all the digits in the string to 0\n","    return re.sub('\\d', '0', s)\n","\n","def loadSentences(path, setzero):\n","    # File is read and loaded as sentences\n","    # Each sentence is separated by an emplty line\n","    sentence = []\n","    sentences_array = []\n","\n","    for line in codecs.open(path, 'r', 'utf8'):\n","        # Remove any trailing characters in the line and replace all digits with zeros\n","        if setzero:\n","            line = replaceDigitsWithZeros(line.rstrip())\n","        else:\n","            line = line.rstrip()\n","\n","        if line:\n","            word = line.split()\n","            # Checks if the length of the word is at least 2 (which is then considered as a word)\n","            assert len(word) >= 2\n","            sentence.append(word)\n","        else:\n","            if len(sentence) > 0:\n","                if 'DOCSTART' not in sentence[0][0]:\n","                    sentences_array.append(sentence)\n","                sentence = []\n","\n","    if len(sentence) > 0:\n","        if 'DOCSTART' not in sentence[0][0]:\n","            sentences_array.append(sentence)\n","\n","    return sentences_array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9M1Rtsk7Z12"},"outputs":[],"source":["# Load train, development and test files into sentences\n","train_sentences = loadSentences(parameters['train'], parameters['setzero'])\n","test_sentences = loadSentences(parameters['test'], parameters['setzero'])\n","dev_sentences = loadSentences(parameters['dev'], parameters['setzero'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bDCRr-U7xNe"},"outputs":[],"source":["def determineBIOFormat(tags):\n","\n","    for i, tag in enumerate(tags):\n","        if tag == 'O':\n","            continue\n","        split = tag.split('-')\n","        # Checks if the tags are in the valid BIO format\n","        if len(split) != 2 or split[0] not in ['I', 'B']:\n","            return False\n","        if split[0] == 'B':\n","            continue\n","\n","        # IOB1 - Most singular word entities are assigned I tag\n","        # IOB2 - Singular word entities are assigned B tag\n","        # Convert IOB1 to IOB2\n","        elif i == 0 or tags[i - 1] == 'O':\n","            tags[i] = 'B' + tag[1:]\n","        elif tags[i - 1][1:] == tag[1:]:\n","            continue\n","        else:\n","            tags[i] = 'B' + tag[1:]\n","    return True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7rRKUcXS_MA"},"outputs":[],"source":["def convertBIOToBIOES(tags):\n","    # BIO - Has \"B\" represents the beginning of an entity, \"I\" represents the inside of an entity, and \"O\" represents outside any entity\n","    # BIOES - Similar to BIO but with the inclusion of  \"E\" to represent the end of an entity and \"S\" for single entities\n","    # Convert BIO to BIOES\n","    convert_tags = []\n","    for i, tag in enumerate(tags):\n","        if tag == 'O':\n","            convert_tags.append(tag)\n","        elif tag.split('-')[0] == 'B':\n","            if i + 1 != len(tags) and \\\n","               tags[i + 1].split('-')[0] == 'I':\n","                convert_tags.append(tag)\n","            else:\n","                convert_tags.append(tag.replace('B-', 'S-'))\n","        elif tag.split('-')[0] == 'I':\n","            if i + 1 < len(tags) and \\\n","                    tags[i + 1].split('-')[0] == 'I':\n","                convert_tags.append(tag)\n","            else:\n","                convert_tags.append(tag.replace('I-', 'E-'))\n","        else:\n","            raise Exception('Error: Invalid BIO format!')\n","    return convert_tags"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XYaT4TFES_MB"},"outputs":[],"source":["def updationOfTagScheme(sentences, tag_scheme):\n","\n","    # Update sentences tagging scheme to BIO2\n","\n","    for i, sentence in enumerate(sentences):\n","        tags = []\n","        for w in sentence:\n","          tags.append(w[-1])\n","        # Check that tags are given in the BIO format\n","        if not determineBIOFormat(tags):\n","            w_str = \"\"\n","            for w in sentence:\n","              w_str = w_str + ' '.join(w)\n","            s_str = '\\n'.join(w_str)\n","            raise Exception('Sentences must be in BIO format! Check sentence %i:\\n%s' % (i, s_str))\n","\n","        if tag_scheme == 'BIOES':\n","            convert_tags = convertBIOToBIOES(tags)\n","\n","            for word, convert_tag in zip(sentence, convert_tags):\n","                word[-1] = convert_tag\n","        else:\n","            raise Exception('Error: Invalid tagging scheme!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bhncEIvd73O2"},"outputs":[],"source":["# Update tagging scheme of sentences to BIO2\n","updationOfTagScheme(train_sentences, parameters['tag_scheme'])\n","updationOfTagScheme(dev_sentences, parameters['tag_scheme'])\n","updationOfTagScheme(test_sentences, parameters['tag_scheme'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IThABWzM7-6_"},"outputs":[],"source":["def creationOfDictionary(list_of_elements):\n","    # Create dictionary of elements from a list of list of elements\n","    # Checks if the input is a list\n","    assert type(list_of_elements) is list\n","\n","    dictionary = {}\n","    for elements in list_of_elements:\n","        for element in elements:\n","            # Count the number of occurrences for each element\n","            if element not in dictionary:\n","                dictionary[element] = 1\n","            else:\n","                dictionary[element] += 1\n","    return dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GH3SYHkZS_MB"},"outputs":[],"source":["def mappingCreation(dictionary):\n","    # Sort the elements(words) by decreasing frequency\n","    sorted_elements = sorted(dictionary.items(), key=lambda x: (-x[1], x[0]))\n","\n","    # a unique id which is the value starting from 0 is given to each unique word which is the key\n","    id_to_elements = {i: v[0] for i, v in enumerate(sorted_elements)}\n","\n","    # a unique id which is the key starting from 0 is given to each unique word which is the value\n","    elements_to_id = {v: k for k, v in id_to_elements.items()}\n","    return elements_to_id, id_to_elements"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKCMJ6WlS_MB"},"outputs":[],"source":["def mappingOfWord(sentences, lower):\n","    # Standardise the word format by converting words to lower case\n","    words = [[x[0].lower() if lower else x[0] for x in s] for s in sentences]\n","\n","    # Define pretrained dictionary\n","    dictionary = creationOfDictionary(words)\n","\n","    # Assign UNK tag for unknown words\n","    dictionary['<UNK>'] = 10000000\n","\n","    # word_to_id -> a unique id which is the value starting from 0 is given to each unique word which is the key\n","    # id_to_word -> a unique id which is the key starting from 0 is given to each unique word which is the value\n","    word_to_id, id_to_word = mappingCreation(dictionary)\n","    print(\"Total unique words (%i in total): %i\" % (sum(len(x) for x in words), len(dictionary)))\n","\n","    return dictionary, word_to_id, id_to_word"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZNqZhd5S_MB"},"outputs":[],"source":["def mappingOfCharacters(sentences):\n","    # Get all the characters in the sentences\n","    characters = [\"\".join([w[0] for w in s]) for s in sentences]\n","\n","    # Create a dictionary containing number of occurences for each unique character\n","    dictionary = creationOfDictionary(characters)\n","\n","    # char_to_id -> a unique id which is the value starting from 0 is given to each unique char which is the key\n","    # id_to_char -> a unique id which is the key starting from 0 is given to each unique char which is the value\n","    char_to_id, id_to_char = mappingCreation(dictionary)\n","    print(\"Total unique characters: %i\" % len(dictionary))\n","    return dictionary, char_to_id, id_to_char"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BbGFMajES_MB"},"outputs":[],"source":["def mappingOfTags(sentences):\n","    # Get all the tags for each word\n","    tags = [[word[-1] for word in s] for s in sentences]\n","\n","    # Create a dictionary containing number of occurences for each unique tag\n","    dictionary = creationOfDictionary(tags)\n","\n","    # Assign '<START>' for START_TAG\n","    # Assign '<STOP>' for STOP_TAG\n","    dictionary[START_TAG] = -1\n","    dictionary[STOP_TAG] = -2\n","\n","    # tag_to_id -> a unique id which is the value starting from 0 is given to each unique tag which is the key\n","    # id_to_tag -> a unique id which is the key starting from 0 is given to each unique tag which is the value\n","    tag_to_id, id_to_tag = mappingCreation(dictionary)\n","    print(\"Total unique named entity tags: %i \" % len(dictionary))\n","    return dictionary, tag_to_id, id_to_tag"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MRDPqdUN8F_I","outputId":"daf6b0ea-670b-477d-e2ae-b153c78111fe","executionInfo":{"status":"ok","timestamp":1699334025441,"user_tz":-480,"elapsed":29,"user":{"displayName":"Code Till","userId":"00349487664103867259"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Total unique words (203621 in total): 17493\n","Total unique characters: 75\n","Total unique named entity tags: 19 \n"]}],"source":["dictionary_words,word_to_id,id_to_word = mappingOfWord(train_sentences, parameters['setlower'])\n","dictionary_chars, char_to_id, id_to_char = mappingOfCharacters(train_sentences)\n","dictionary_tags, tag_to_id, id_to_tag = mappingOfTags(train_sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBqU9V4x8KDo"},"outputs":[],"source":["def lower_case(x,lower=False):\n","    # Performs lower case on words\n","    if lower:\n","        return x.lower()\n","    else:\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"AFVP8kOpS_MC"},"source":["**Question 1.2**\n","\n","(a) Describe the size (number of sentences) of the training, development and test file for CoNLL2003.\n","Specify the complete set of all possible word labels based on the tagging scheme (IO, BIO,\n","etc.) you chose."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OuyEzicX8LTw","outputId":"a36d355c-7fe6-42e2-e418-839dc239d73f","executionInfo":{"status":"ok","timestamp":1699334025441,"user_tz":-480,"elapsed":26,"user":{"displayName":"Code Till","userId":"00349487664103867259"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of sentences in train set: 14041\n","Number of sentences in development set: 3250\n","Number of sentences in test set: 3453\n"]}],"source":["def datasetPreparation(sentences, word_to_id, char_to_id, tag_to_id, lower=False):\n","    data = []\n","    for sentence in sentences:\n","        # Get all the words in the sentence\n","        str_words = [word[0] for word in sentence]\n","\n","        # Convert all the words to lower case\n","        # Unknown words will be labelled as <UNK>\n","        words = [word_to_id[lower_case(word,lower) if lower_case(word,lower) in word_to_id else '<UNK>'] for word in str_words]\n","\n","        # Get the characters\n","        characters = [[char_to_id[c] for c in w if c in char_to_id] for w in str_words]\n","\n","        # Get the tags\n","        tags = []\n","        for word in sentence:\n","            tags.append(tag_to_id[word[-1]])\n","\n","        # Appends lists of dictionaries into a list\n","        data.append({\n","            'str_words': str_words,\n","            'words': words,\n","            'chars': characters,\n","            'tags': tags,\n","        })\n","\n","    return data\n","\n","train_data = datasetPreparation(train_sentences, word_to_id, char_to_id, tag_to_id, parameters['setlower'])\n","dev_data = datasetPreparation(dev_sentences, word_to_id, char_to_id, tag_to_id, parameters['setlower'])\n","test_data = datasetPreparation(test_sentences, word_to_id, char_to_id, tag_to_id, parameters['setlower'])\n","\n","print(\"Number of sentences in train set: \" + str(len(train_data)))\n","print(\"Number of sentences in development set: \" + str(len(dev_data)))\n","print(\"Number of sentences in test set: \" + str(len(test_data)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDDMhnkj9zi7","outputId":"711ea4b2-1455-45ca-8ffa-a400d54dafe5","executionInfo":{"status":"ok","timestamp":1699334025442,"user_tz":-480,"elapsed":25,"user":{"displayName":"Code Till","userId":"00349487664103867259"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["   Word Labels       #\n","0        S-ORG    3836\n","1            O  169578\n","2       S-MISC    2580\n","3        B-PER    4284\n","4        E-PER    4284\n","5        S-LOC    6099\n","6        B-ORG    2485\n","7        E-ORG    2485\n","8        I-PER     244\n","9        S-PER    2316\n","10      B-MISC     858\n","11      I-MISC     297\n","12      E-MISC     858\n","13       I-ORG    1219\n","14       B-LOC    1041\n","15       E-LOC    1041\n","16       I-LOC     116\n","17     <START>      -1\n","18      <STOP>      -2\n"]}],"source":["df = pd.DataFrame(list(dictionary_tags.items()), columns=['Word Labels', '#'])\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"IktI9apWS_MD"},"source":["The dataframe above shows the complete set of all possible word labels based on the BIOES tagging scheme."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tXhSlVegS_MD"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Ti5ER3FMS_MD"},"source":["(b) Choose an example sentence from the training set of CoNLL2003 that has at least two named\n","entities with more than one word. Explain how to form complete named entities from the label\n","for each word, and list all the named entities in this sentence."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43bMg6o0OGAZ"},"outputs":[],"source":["sentences_bio_train = loadSentences(parameters['train'], parameters['setzero'])\n","df_sentences_bio_train = pd.DataFrame(sentences_bio_train[7728], columns=['Word', 'POS', 'Chunk', 'BIO']).drop(columns=['POS', 'Chunk'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOlXGK9CAhBM"},"outputs":[],"source":["df_sentences_bioes_train = pd.DataFrame(train_sentences[7728], columns=['Word', 'POS', 'Chunk', 'BIOES']).drop(columns=['POS', 'Chunk'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-4NJk52iO9nu","outputId":"3191edcc-9cbc-45c7-e447-a9d3bd408e6e","executionInfo":{"status":"ok","timestamp":1699334025442,"user_tz":-480,"elapsed":23,"user":{"displayName":"Code Till","userId":"00349487664103867259"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Data with BIO tagging scheme VS Data with BIOES tagging scheme\n"]},{"output_type":"execute_result","data":{"text/plain":["               Word    BIO             Word  BIOES\n","0                He      O               He      O\n","1               has      O              has      O\n","2             spent      O            spent      O\n","3               his      O              his      O\n","4             adult      O            adult      O\n","5              life      O             life      O\n","6                in      O               in      O\n","7          politics      O         politics      O\n","8                 ,      O                ,      O\n","9            coming      O           coming      O\n","10               to      O               to      O\n","11         Congress  I-ORG         Congress  S-ORG\n","12               as      O               as      O\n","13               an      O               an      O\n","14             aide      O             aide      O\n","15               in      O               in      O\n","16             0000      O             0000      O\n","17            after      O            after      O\n","18            three      O            three      O\n","19            years      O            years      O\n","20               in      O               in      O\n","21              the      O              the      O\n","22              Air  I-ORG              Air  B-ORG\n","23            Force  I-ORG            Force  E-ORG\n","24              and      O              and      O\n","25             then      O             then      O\n","26            being      O            being      O\n","27          elected      O          elected      O\n","28               to      O               to      O\n","29              the      O              the      O\n","30            House  I-ORG            House  B-ORG\n","31               of  I-ORG               of  I-ORG\n","32  Representatives  I-ORG  Representatives  E-ORG\n","33          himself      O          himself      O\n","34               in      O               in      O\n","35             0000      O             0000      O\n","36                .      O                .      O"],"text/html":["\n","  <div id=\"df-cc4094a5-c7b8-470c-a3c5-ac5eb89b3f51\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Word</th>\n","      <th>BIO</th>\n","      <th>Word</th>\n","      <th>BIOES</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>He</td>\n","      <td>O</td>\n","      <td>He</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>has</td>\n","      <td>O</td>\n","      <td>has</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spent</td>\n","      <td>O</td>\n","      <td>spent</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>his</td>\n","      <td>O</td>\n","      <td>his</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>adult</td>\n","      <td>O</td>\n","      <td>adult</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>life</td>\n","      <td>O</td>\n","      <td>life</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>in</td>\n","      <td>O</td>\n","      <td>in</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>politics</td>\n","      <td>O</td>\n","      <td>politics</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>,</td>\n","      <td>O</td>\n","      <td>,</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>coming</td>\n","      <td>O</td>\n","      <td>coming</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>to</td>\n","      <td>O</td>\n","      <td>to</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Congress</td>\n","      <td>I-ORG</td>\n","      <td>Congress</td>\n","      <td>S-ORG</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>as</td>\n","      <td>O</td>\n","      <td>as</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>an</td>\n","      <td>O</td>\n","      <td>an</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>aide</td>\n","      <td>O</td>\n","      <td>aide</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>in</td>\n","      <td>O</td>\n","      <td>in</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0000</td>\n","      <td>O</td>\n","      <td>0000</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>after</td>\n","      <td>O</td>\n","      <td>after</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>three</td>\n","      <td>O</td>\n","      <td>three</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>years</td>\n","      <td>O</td>\n","      <td>years</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>in</td>\n","      <td>O</td>\n","      <td>in</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>the</td>\n","      <td>O</td>\n","      <td>the</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Air</td>\n","      <td>I-ORG</td>\n","      <td>Air</td>\n","      <td>B-ORG</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Force</td>\n","      <td>I-ORG</td>\n","      <td>Force</td>\n","      <td>E-ORG</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>and</td>\n","      <td>O</td>\n","      <td>and</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>then</td>\n","      <td>O</td>\n","      <td>then</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>being</td>\n","      <td>O</td>\n","      <td>being</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>elected</td>\n","      <td>O</td>\n","      <td>elected</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>to</td>\n","      <td>O</td>\n","      <td>to</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>the</td>\n","      <td>O</td>\n","      <td>the</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>House</td>\n","      <td>I-ORG</td>\n","      <td>House</td>\n","      <td>B-ORG</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>of</td>\n","      <td>I-ORG</td>\n","      <td>of</td>\n","      <td>I-ORG</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Representatives</td>\n","      <td>I-ORG</td>\n","      <td>Representatives</td>\n","      <td>E-ORG</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>himself</td>\n","      <td>O</td>\n","      <td>himself</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>in</td>\n","      <td>O</td>\n","      <td>in</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0000</td>\n","      <td>O</td>\n","      <td>0000</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>.</td>\n","      <td>O</td>\n","      <td>.</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc4094a5-c7b8-470c-a3c5-ac5eb89b3f51')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cc4094a5-c7b8-470c-a3c5-ac5eb89b3f51 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cc4094a5-c7b8-470c-a3c5-ac5eb89b3f51');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c6354a13-7147-4669-acc0-31af2f3a7680\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6354a13-7147-4669-acc0-31af2f3a7680')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c6354a13-7147-4669-acc0-31af2f3a7680 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":24}],"source":["result = pd.concat([df_sentences_bio_train, df_sentences_bioes_train], axis=1)\n","print(\"Data with BIO tagging scheme VS Data with BIOES tagging scheme\")\n","result"]},{"cell_type":"markdown","metadata":{"id":"TH8lgnYXFc_j"},"source":["We made use of the BIOES tagging scheme as it gives a more accurate representation when differientiating multi-word and single-word entities as compared to BIO.\n","\n","If it was in BIO, the labels of the named entity \"House of Representatives\" would be all \"I-ORG\". If it is in BIOES, the labels of the named entity \"House of Representatives\" would be all \"B-ORG\", \"I-ORG\" and \"E-ORG\" respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pl9AnU7rS_MK"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"q1oTxPJ4SW6O"},"source":["**Question 1.3**"]},{"cell_type":"markdown","source":["Please view the report for our answers to question 1.3."],"metadata":{"id":"e7dPytk_wRu7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnrIbhg4T_mt"},"outputs":[],"source":["from __future__ import print_function\n","from collections import OrderedDict\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import init\n","from torch.autograd import Variable\n","from torch import autograd\n","\n","import time\n","import _pickle as cPickle\n","\n","import urllib\n","import matplotlib.pyplot as plt\n","plt.rcParams['figure.dpi'] = 80\n","plt.style.use('ggplot')\n","\n","import os\n","import sys\n","import codecs\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vG29wujySYCk"},"outputs":[],"source":["def initialisationOfEmbedding(input_embedding):\n","    # Intiliase embedding\n","    bias = np.sqrt(3.0 / input_embedding.size(1))\n","\n","    # Fills the input Tensor with values drawn from the uniform distribution\n","    nn.init.uniform_(input_embedding, -bias, bias)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6BnR7jtSd2p"},"outputs":[],"source":["def initialisationOfLinearTransformation(input):\n","    # Initialiase linear transformation\n","    total_weight_size = input.weight.size(0) + input.weight.size(1)\n","    bias = np.sqrt(6.0 / total_weight_size)\n","\n","    # Fills the input Tensor with values drawn from the uniform distribution\n","    nn.init.uniform_(input.weight, -bias, bias)\n","\n","    if input.bias is not None:\n","        input.bias.data.zero_()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkehO9crSmZB"},"outputs":[],"source":["def initialisationOfLSTM(lstm):\n","    # INITIALISATION OF WEIGHTS\n","    # Iterate through the number of recurrent layer in LSTM\n","    for index in range(0, lstm.num_layers):\n","\n","        # Get the weights Tensor from our model, for the (input layer to hidden layer) weights in our current layer\n","        weight = eval('lstm.weight_ih_l' + str(index))\n","\n","        # Define sampling range\n","        sampling_range = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n","\n","        # Randomly sample from our sampling range using uniform distribution and apply it to our current layer\n","        nn.init.uniform_(weight, -sampling_range, sampling_range)\n","\n","        # Get the weights Tensor from our model, for the (hidden layer to hidden layer) weights of the current layer\n","        weight = eval('lstm.weight_hh_l' + str(index))\n","\n","        # Define sampling range\n","        sampling_range = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n","\n","        # Randomly sample from our sampling range using uniform distribution and apply it to our current layer\n","        nn.init.uniform_(weight, -sampling_range, sampling_range)\n","\n","\n","    # Checks if bidirectional LSTM is used for the backward layer\n","    if lstm.bidirectional:\n","\n","        for index in range(0, lstm.num_layers):\n","            # Get the weights Tensor from our model, for the (input layer to hidden layer) weights in our current layer for the reverse direction\n","            weight = eval('lstm.weight_ih_l' + str(index) + '_reverse')\n","\n","            # Define sampling range\n","            sampling_range = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n","\n","            # Randomly sample from our sampling range using uniform distribution and apply it to our current layer\n","            nn.init.uniform_(weight, -sampling_range, sampling_range)\n","\n","            # Get the weights Tensor from our model, for the (hidden layer to hidden layer) weights of the current layer for the reverse direction\n","            weight = eval('lstm.weight_hh_l' + str(index) + '_reverse')\n","\n","            # Define sampling range\n","            sampling_range = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n","\n","            # Randomly sample from our sampling range using uniform distribution and apply it to our current layer\n","            nn.init.uniform_(weight, -sampling_range, sampling_range)\n","\n","    # INITIALISATION OF BIAS\n","    # We initialize them to zero except for the forget gate bias, which is initialized to 1\n","    if lstm.bias:\n","        for index in range(0, lstm.num_layers):\n","\n","            # Get the bias Tensor from our model, for the (input layer to hidden layer) weights in our current layer\n","            bias = eval('lstm.bias_ih_l' + str(index))\n","\n","            # Initialising to zero\n","            bias.data.zero_()\n","\n","            # This is the range of indices for our forget gates for each LSTM cell\n","            bias.data[lstm.hidden_size: 2 * lstm.hidden_size] = 1\n","\n","            # Get the bias Tensor from our model, for the (hidden layer to hidden layer) weights in our current layer\n","            bias = eval('lstm.bias_hh_l' + str(index))\n","            bias.data.zero_()\n","            bias.data[lstm.hidden_size: 2 * lstm.hidden_size] = 1\n","\n","        # Checks if bidirectional LSTM is used\n","        if lstm.bidirectional:\n","            for index in range(0, lstm.num_layers):\n","                bias = eval('lstm.bias_ih_l' + str(index) + '_reverse')\n","                bias.data.zero_()\n","                bias.data[lstm.hidden_size: 2 * lstm.hidden_size] = 1\n","                bias = eval('lstm.bias_hh_l' + str(index) + '_reverse')\n","                bias.data.zero_()\n","                bias.data[lstm.hidden_size: 2 * lstm.hidden_size] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sQzqMivmSqj0"},"outputs":[],"source":["def log_sum_exp(vector):\n","    # Get the maximum score in the vector for the forward algorithm\n","    maximum_score = vector[0, argmax(vector)]\n","    maximum_score_broadcast = maximum_score.view(1, -1).expand(1, vector.size()[1])\n","    return maximum_score + torch.log(torch.sum(torch.exp(vector - maximum_score_broadcast)))\n","\n","def argmax(vec):\n","    # Get the max index in a vector\n","    _, idx = torch.max(vec, 1)\n","    return to_scalar(idx)\n","\n","def to_scalar(var):\n","    # Convert pytorch tensor to a scalar\n","    return var.view(-1).data.tolist()[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EVWLHa4aTAd_"},"outputs":[],"source":["def scoreSentences(self, feats, tags):\n","    row_indices = torch.LongTensor(range(feats.size()[0]))\n","\n","    if self.use_gpu:\n","        # Change to tensor\n","        row_indices = row_indices.cuda()\n","\n","        # Concatenate tensors along a specified dimension\n","        start_tags_with_padding = torch.cat([torch.cuda.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n","        stop_tags_with_padding = torch.cat([tags, torch.cuda.LongTensor([self.tag_to_ix[STOP_TAG]])])\n","    else:\n","        # Concatenate tensors along a specified dimension\n","        start_tags_with_padding = torch.cat([torch.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n","        stop_tags_with_padding = torch.cat([tags, torch.LongTensor([self.tag_to_ix[STOP_TAG]])])\n","\n","    return torch.sum(self.transitions[stop_tags_with_padding, start_tags_with_padding]) + torch.sum(feats[row_indices, tags])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJbLFyPMTA8a"},"outputs":[],"source":["def executionOfForwardAlgorithm(self, features):\n","    # Performs Forward Algorithm\n","\n","    # initialise alpha with a Tensor with values all equal to -10000.\n","    initialise_alphas = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n","\n","    # Initliase alpha with START TAG value from the dictionary that maps NER tags to indices to 0\n","    initialise_alphas[0][self.tag_to_ix[START_TAG]] = 0\n","\n","    # Ensure automatic backpropogation\n","    forward_variable = autograd.Variable(initialise_alphas)\n","    if self.use_gpu:\n","        forward_variable = forward_variable.cuda()\n","\n","    # Loop through the sentence\n","    for feature in features:\n","        # Get emission score by reshaping the tensor into a 2-dimensional tensor with 10 rows and 1 column\n","        emit_score = feature.view(-1, 1)\n","\n","        # Compute the score of transitioning to next_tag from current tag\n","        current_tag_var = forward_variable + self.transitions + emit_score\n","\n","        # Compute the maximum value along each row of the tag_var tensor, representing the most likely tag transition for each current tag.\n","        max_tag_var, _ = torch.max(current_tag_var, dim=1)\n","\n","        # Get the forward variable for the tag\n","        current_tag_var = current_tag_var - max_tag_var.view(-1, 1)\n","\n","        # Compute log sum exp for the forward algorithm\n","        forward_variable = max_tag_var + torch.log(torch.sum(torch.exp(current_tag_var), dim=1)).view(1, -1) # ).view(1, -1)\n","\n","    # Compute the terminal variable\n","    terminal_var = (forward_variable + self.transitions[self.tag_to_ix[STOP_TAG]]).view(1, -1)\n","\n","    # Compute alpha\n","    alpha = log_sum_exp(terminal_var)\n","\n","    return alpha"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWxmyG9FTSSu"},"outputs":[],"source":["def executionOfViterbiAlgo(self, features):\n","\n","    # Finding the best tag sequence using viterbi algorithm\n","    backpointers = []\n","    # analogous to forward\n","\n","    # Initialize the viterbi variables\n","    initialise_vvars = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n","\n","    # Initliase viterbi variable with START TAG value from the dictionary that maps NER tags to indices to 0\n","    initialise_vvars[0][self.tag_to_ix[START_TAG]] = 0\n","\n","    # Initliase forward variable\n","    forward_variable = Variable(initialise_vvars)\n","    if self.use_gpu:\n","        forward_variable = forward_variable.cuda()\n","    # Loop through the sentence\n","    for feature in features:\n","        # Compute the scores for transitioning from the previous tags to the next tags\n","        next_tag_var = forward_variable.view(1, -1).expand(self.tagset_size, self.tagset_size) + self.transitions\n","\n","        # Find the tag indices that maximize the scores\n","        _, bptrs_tensor = torch.max(next_tag_var, dim=1)\n","\n","         # Convert to numpy array\n","        next_tag_var = next_tag_var.data.cpu().numpy()\n","        bptrs_tensor = bptrs_tensor.squeeze().data.cpu().numpy()\n","\n","        # Extract the Viterbi variables\n","        viterbivars_tensor = next_tag_var[range(len(bptrs_tensor)), bptrs_tensor]\n","\n","        # Convert the Viterbi variables to a PyTorch Variable\n","        # viterbivars_tensor = Variable(torch.FloatTensor(viterbivars_tensor))\n","        viterbivars_tensor = Variable(torch.FloatTensor(viterbivars_tensor))\n","\n","        if self.use_gpu:\n","            viterbivars_tensor = viterbivars_tensor.cuda()\n","\n","        # Store the backpointers in the list\n","        backpointers.append(bptrs_tensor)\n","\n","        # Compute forward variable to the set of viterbi variables\n","        forward_variable = viterbivars_tensor + feature\n","        backpointers.append(bptrs_tensor)\n","\n","    # Transition to STOP_TAG\n","    terminal_variable = forward_variable + self.transitions[self.tag_to_ix[STOP_TAG]]\n","    terminal_variable.data[self.tag_to_ix[STOP_TAG]] = -10000.\n","    terminal_variable.data[self.tag_to_ix[START_TAG]] = -10000.\n","    best_tag_id = argmax(terminal_variable.unsqueeze(0))\n","    path_score = terminal_variable[best_tag_id]\n","\n","    # Find best path by retracing backpointers\n","    best_path = [best_tag_id]\n","    for bptrs_tensor in reversed(backpointers):\n","        best_tag_id = bptrs_tensor[best_tag_id]\n","        best_path.append(best_tag_id)\n","\n","    # Remove the start tag from best path sequence\n","    start = best_path.pop()\n","    assert start == self.tag_to_ix[START_TAG]\n","    best_path.reverse()\n","    return path_score, best_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j8TvoQBLTbNv"},"outputs":[],"source":["def forward_calc(self, sentence, chars, chars2_length, d):\n","\n","    # Get the emission scores from the BiLSTM\n","    features = self._get_lstm_features(sentence, chars, chars2_length, d)\n","\n","    # If CRF = True, perform Viterbi decoding to find the best tag sequence\n","    if self.use_crf:\n","\n","        # Find the best tag sequence and its score\n","        score, tag_sequence = self.viterbi_decode(features)\n","    else:\n","\n","        # Find the maximum score and corresponding tag index for each position along the sequence\n","        score, tag_sequence = torch.max(features, 1)\n","\n","        # Convert the tensor to a list containing the tag indices\n","        tag_sequence = list(tag_sequence.cpu().data)\n","\n","    # Return the maximum score and the predicted tag sequence\n","    return score, tag_sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYQHV_TlTckU"},"outputs":[],"source":["def retrievalOfLSTMFeatures(self, sentence, chars2, chars2_length, d):\n","\n","    # Embed character-level representations\n","    characters_embeddings = self.char_embeds(chars2).transpose(0, 1)\n","    packed = torch.nn.utils.rnn.pack_padded_sequence(characters_embeddings, chars2_length)\n","    lstm_out, _ = self.char_lstm(packed)\n","\n","    # Unpack the LSTM outputs and transpose the tensor for further processing\n","    outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm_out)\n","    outputs = outputs.transpose(0, 1)\n","\n","    # Initialize a tensor to store character-level representations\n","    characters_embeddings_temp = Variable(torch.FloatTensor(torch.zeros((outputs.size(0), outputs.size(2)))))\n","\n","    if self.use_gpu:\n","        characters_embeddings_temp = characters_embeddings_temp.cuda()\n","\n","    # Extract the last and first hidden states from the character-level LSTM for each word\n","    for i, index in enumerate(output_lengths):\n","        characters_embeddings_temp[i] = torch.cat((outputs[i, index-1, :25], outputs[i, 0, 25:]))\n","\n","    characters_embeddings = characters_embeddings_temp.clone()\n","\n","    # Reorder the character-level representations\n","    for i in range(characters_embeddings.size(0)):\n","        characters_embeddings[d[i]] = characters_embeddings_temp[i]\n","\n","    # Embed words using word embeddings\n","    embeddings = self.word_embeds(sentence)\n","\n","    # Concatenate word embeddings with the reordered embeddings\n","    embeddings = torch.cat((embeddings, characters_embeddings), 1)\n","\n","    embeddings = embeddings.unsqueeze(1)\n","\n","    # Apply dropout\n","    embeddings = self.dropout(embeddings)\n","\n","    lstm_out, _ = self.lstm(embeddings)\n","\n","    # Reshape the LSTM outputs\n","    lstm_out = lstm_out.view(len(sentence), self.hidden_dim*2)\n","\n","    # Apply dropout\n","    lstm_out = self.dropout(lstm_out)\n","\n","    # Apply linear transformation\n","    lstm_features = self.hidden2tag(lstm_out)\n","\n","    return lstm_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6KO3SOSTvS_"},"outputs":[],"source":["# Find the loss\n","def retrievalOfNegLogLikelihood(self, sentence, tags, chars2, chars2_length, d):\n","    # Get LSTM features\n","    features = self._get_lstm_features(sentence, chars2, chars2_length, d)\n","\n","    if self.use_crf:\n","        # Get forward score based on the LSTM features\n","        forward_score = self._forward_alg(features)\n","\n","        score = self._score_sentence(features, tags)\n","        return forward_score - score\n","    else:\n","        tags = Variable(tags)\n","        scores = nn.functional.cross_entropy(features, tags)\n","        return scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ASuAnpGaTxHQ"},"outputs":[],"source":["class BiLSTM_CRF(nn.Module):\n","\n","    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim,\n","                 char_to_ix=None, pre_word_embeds=None, char_out_dimension=25,char_embedding_dim=25, use_gpu=False\n","                 , use_crf=True):\n","\n","        super(BiLSTM_CRF, self).__init__()\n","\n","        #parameter initialization for the model\n","\n","        # Checks if using GPU\n","        self.use_gpu = use_gpu\n","\n","        # Get the dimension of the word embeddings\n","        self.embedding_dim = embedding_dim\n","\n","        # Get the dimensions of the hidden LSTM layer\n","        self.hidden_dim = hidden_dim\n","\n","        # Get the vocabulary size\n","        self.vocab_size = vocab_size\n","\n","        # Gets dictionary that maps NER tags to indices\n","        self.tag_to_ix = tag_to_ix\n","\n","        # Checks if using CRF\n","        self.use_crf = use_crf\n","\n","        # Get tagset size\n","        self.tagset_size = len(tag_to_ix)\n","\n","        # Get output dimension from the CNN encoder\n","        self.out_channels = char_out_dimension\n","\n","        print(\"tagset size:\")\n","        print(len(tag_to_ix))\n","\n","        # Checks if dimension of the character embeddings is stated\n","        if char_embedding_dim is not None:\n","            self.char_embedding_dim = char_embedding_dim\n","\n","            #Initialise the character embedding layer\n","            self.char_embeds = nn.Embedding(len(char_to_ix), char_embedding_dim)\n","            initialisationOfEmbedding(self.char_embeds.weight)\n","\n","            #Performing LSTM encoding on the character embeddings\n","            self.char_lstm = nn.LSTM(char_embedding_dim, 25, num_layers=1, bidirectional=True)\n","            initialisationOfLSTM(self.char_lstm)\n","\n","        # Get Embedding layer\n","        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n","\n","        if pre_word_embeds is not None:\n","\n","            #Initialise the word embeddings with pretrained word embeddings\n","            self.pre_word_embeds = True\n","            self.word_embeds.weight = nn.Parameter(torch.FloatTensor(pre_word_embeds))\n","\n","        else:\n","            self.pre_word_embeds = False\n","\n","        # Initialise the dropout layer\n","        self.dropout = nn.Dropout(parameters['dropout'])\n","\n","        # Initialise Lstm Layer\n","        self.lstm = nn.LSTM(embedding_dim+25*2, hidden_dim, bidirectional=True)\n","        initialisationOfLSTM(self.lstm)\n","\n","        # Initialise Linear layer\n","        self.hidden2tag = nn.Linear(hidden_dim*2, self.tagset_size)\n","\n","        #Initializing the linear layer using predefined function for initialization\n","        initialisationOfLinearTransformation(self.hidden2tag)\n","\n","        # Checks if crf = True\n","        if self.use_crf:\n","            # Initialise transition scores which represent the likelihoods of transitioning between different tags\n","            self.transitions = nn.Parameter(torch.zeros(self.tagset_size, self.tagset_size))\n","\n","            # Ensure transitions does not occur from start tag and also from stop tag\n","            self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n","            self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n","\n","    # Assigning the functions\n","    _score_sentence = scoreSentences\n","    _get_lstm_features = retrievalOfLSTMFeatures\n","    _forward_alg = executionOfForwardAlgorithm\n","    viterbi_decode = executionOfViterbiAlgo\n","    neg_log_likelihood = retrievalOfNegLogLikelihood\n","    forward = forward_calc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9N_R-KMwTz8K","outputId":"8f358750-09e2-48a3-ba2c-0fe7fb3e8b4f","executionInfo":{"status":"ok","timestamp":1699334025444,"user_tz":-480,"elapsed":18,"user":{"displayName":"Code Till","userId":"00349487664103867259"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tagset size:\n","19\n","Model Initialized!!!\n"]}],"source":["# Initiliase Model\n","model = BiLSTM_CRF(vocab_size=len(word_to_id),\n","                   tag_to_ix=tag_to_id,\n","                   embedding_dim=parameters['word_dim'],\n","                   hidden_dim=parameters['word_lstm_dim'],\n","                   use_gpu=use_gpu,\n","                   char_to_ix=char_to_id,\n","                   pre_word_embeds=w2v.vectors,\n","                   use_crf=parameters['crf'])\n","print(\"Model Initialized!!!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIr51OgbUKZp"},"outputs":[],"source":["#Initialising the optimizer\n","learning_rate = 0.015\n","momentum = 0.9\n","decay_rate = 0.05\n","gradient_clip = parameters['gradient_clip']\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n","\n","#variables which will used in training process\n","# Store all losses\n","losses = []\n","\n","# Initialise loss\n","loss = 0.0\n","\n","# Initliase F1 scores variables for development, test, training sets\n","best_dev_F1_score = -1.0\n","best_test_F1_score = -1.0\n","best_train_F1_score = -1.0\n","\n","# Store all the F-1 Scores\n","all_F1_Scores = [[0, 0, 0]]\n","\n","# Calculate F-1 Score after a certain number of iterations\n","eval_every = len(train_data)\n","\n","# Store loss after a certain number of iterations\n","plot_every = 2000\n","\n","# Counts the number of iterations\n","count = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4UE1CHOtbPeN"},"outputs":[],"source":["def retrievalOfChunkType(token, index_to_tag):\n","    # Splits the chunk into tag and its class\n","    tag_name = index_to_tag[token]\n","    tag_class = tag_name.split('-')[0]\n","    tag_type = tag_name.split('-')[-1]\n","    return tag_class, tag_type"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbIcuL2zbkan"},"outputs":[],"source":["def retrievalOfChunks(seq, tags):\n","    # Retrieve tags\n","    default = tags[\"O\"]\n","\n","    # Create a dictionary which index is the key while the tag is the value\n","    index_to_tag = {idx: tag for tag, idx in tags.items()}\n","\n","    chunks_array = []\n","\n","    chunk_type, chunk_start = None, None\n","    for i, token in enumerate(seq):\n","\n","        if token == default and chunk_type is not None:\n","\n","            # Append a chunk to chunks_array\n","            chunk = (chunk_type, chunk_start, i)\n","            chunks_array.append(chunk)\n","            chunk_type, chunk_start = None, None\n","\n","        # Checks if token is 'O'\n","        elif token != default:\n","            token_chunk_class, token_chunk_type = retrievalOfChunkType(token, index_to_tag)\n","            if chunk_type is None:\n","\n","                # Initialise chunk for each entity\n","                chunk_type, chunk_start = token_chunk_type, i\n","\n","            # Checks for chunk class\n","            elif token_chunk_type != chunk_type or token_chunk_class == \"B\":\n","                chunk = (chunk_type, chunk_start, i)\n","                chunks_array.append(chunk)\n","                chunk_type, chunk_start = token_chunk_type, i\n","\n","        else:\n","            pass\n","\n","    if chunk_type is not None:\n","        chunk = (chunk_type, chunk_start, len(seq))\n","        chunks_array.append(chunk)\n","\n","    return chunks_array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SbxhtEN3bmT3"},"outputs":[],"source":["def performEvaluation(model, datas, best_F1_score, dataset=\"Train\"):\n","    # Stores predicted tags\n","    prediction = []\n","\n","    # Checks if the model should be saved\n","    save = False\n","\n","    # Initialize F1_score\n","    new_F1_Score = 0.0\n","\n","    # Count variables for correct predictions, total correct predictions, and total predictions\n","    correct_predictions, total_correct, total_predictions = 0., 0., 0.\n","\n","    # Iterate through the data\n","    for data in datas:\n","\n","      # True tags for the current data instance\n","        ground_truth_id = data['tags']\n","\n","        # Words in the current data instance\n","        words = data['str_words']\n","\n","        # Character-level representations for words\n","        chars2 = data['chars']\n","\n","        # Sort character-level representations by length for efficient computation\n","        chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n","        d = {}\n","\n","        # Create a mapping between original indices and sorted indices for characters\n","        for i, ci in enumerate(chars2):\n","            for j, cj in enumerate(chars2_sorted):\n","                if ci == cj and not j in d and not i in d.values():\n","                    d[j] = i\n","                    continue\n","        chars2_length = [len(c) for c in chars2_sorted]\n","        char_maxl = max(chars2_length)\n","        chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n","\n","        for i, character in enumerate(chars2_sorted):\n","            chars2_mask[i, :chars2_length[i]] = character\n","\n","        chars2_mask = Variable(torch.LongTensor(chars2_mask))\n","\n","        # Convert the list of words into a PyTorch tensor of data type\n","        data_words = Variable(torch.LongTensor(data['words']))\n","\n","        data_words = data_words.to('cuda')\n","        chars2_mask = chars2_mask.to('cuda')\n","\n","        # Get Predictions\n","        if use_gpu:\n","            val, out = model(data_words.cuda(), chars2_mask.cuda(), chars2_length, d)\n","        else:\n","            val, out = model(data_words, chars2_mask, chars2_length, d)\n","\n","        predicted_id = out\n","\n","        # Get true and predicted chunks for evaluation\n","        lab_chunks = set(retrievalOfChunks(ground_truth_id, tag_to_id))\n","        lab_pred_chunks = set(retrievalOfChunks(predicted_id, tag_to_id))\n","\n","        correct_predictions += len(lab_chunks & lab_pred_chunks)\n","        total_predictions += len(lab_pred_chunks)\n","        total_correct += len(lab_chunks)\n","\n","    # Calculate precision, recall, and F1-Score\n","\n","    if correct_predictions > 0:\n","      precision = correct_predictions / total_predictions\n","      recall = correct_predictions / total_correct\n","      new_F1_Score = 2 * precision * recall / (precision + recall)\n","    else:\n","      precision = 0\n","      recall = 0\n","      new_F1_Score = 0\n","\n","    print(\"{}: new_F1_Score: {} best_F1_score: {} \".format(dataset, new_F1_Score, best_F1_score))\n","\n","    # Update the F1_score with the best F1_score\n","    if new_F1_Score > best_F1_score:\n","        best_F1_score = new_F1_Score\n","        save = True\n","\n","    return best_F1_score, new_F1_Score, save"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQKMcT_vbo9S"},"outputs":[],"source":["def adjustLearningRate(optimizer, learning_rate):\n","    # Reduce learning rate\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = learning_rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A6O2NRkbbqh6"},"outputs":[],"source":["import time\n","import _pickle as cPickle\n","from torch.autograd import Variable\n","from torch import autograd\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKDyqw9Zi90R"},"outputs":[],"source":["parameters['reload']=False"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"HAOvjCo1lXq0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699334068441,"user_tz":-480,"elapsed":15511,"user":{"displayName":"Code Till","userId":"00349487664103867259"}},"outputId":"2e77a43d-7b6f-4033-de06-f56da99a4d46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mf5Si0t5bu9k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb23c6e5-499a-44d5-ac69-447a931c7b87"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------- Epoch 1 --------------\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-30-9673b0c67e8a>:9: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n","  start_tags_with_padding = torch.cat([torch.cuda.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n"]},{"output_type":"stream","name":"stdout","text":["2000 :  0.5522299778563758\n","4000 :  0.25782368293091373\n","6000 :  0.19516489536330967\n","8000 :  0.16203415877294766\n","10000 :  0.1493797413448389\n","12000 :  0.1293671415964332\n","14000 :  0.11344206438027148\n","Train: new_F1_Score: 0.0038588754134509366 best_F1_score: -1.0 \n","Dev: new_F1_Score: 0.004708375022070507 best_F1_score: 0.0 \n","Test: new_F1_Score: 0.0032389635316698658 best_F1_score: -1.0 \n","F1 Score of Test Set(Epoch1): 0.0032389635316698658\n","F1 Score of Development Set(Epoch1): 0.004708375022070507\n","Saving Model\n","The running time to run each epoch: 3289.4680638313293 s\n","-------------- Epoch 2 --------------\n","16000 :  0.08872051436250757\n","18000 :  0.07983936756161944\n","20000 :  0.07713142587643271\n","22000 :  0.07031296797524343\n","24000 :  0.06499001109209744\n","26000 :  0.07258709765849695\n","28000 :  0.05208072451239837\n","Train: new_F1_Score: 0.0031744148099801224 best_F1_score: 0.0038588754134509366 \n","Dev: new_F1_Score: 0.0035279805352798053 best_F1_score: 0.004708375022070507 \n","Test: new_F1_Score: 0.002115480338476854 best_F1_score: 0.0032389635316698658 \n","F1 Score of Test Set(Epoch2): 0.002115480338476854\n","F1 Score of Development Set(Epoch2): 0.0035279805352798053\n","The running time to run each epoch: 2918.7407414913177 s\n","-------------- Epoch 3 --------------\n","30000 :  0.04271275091618329\n","32000 :  0.03464456954959714\n","34000 :  0.05290799626705991\n","36000 :  0.03844789970907775\n","38000 :  0.04399509331182097\n","40000 :  0.04455220374872002\n","42000 :  0.033208939886481194\n","Train: new_F1_Score: 0.0026710499280871167 best_F1_score: 0.0038588754134509366 \n","Dev: new_F1_Score: 0.004057279236276849 best_F1_score: 0.004708375022070507 \n","Test: new_F1_Score: 0.0025713236194441044 best_F1_score: 0.0032389635316698658 \n","F1 Score of Test Set(Epoch3): 0.0025713236194441044\n","F1 Score of Development Set(Epoch3): 0.004057279236276849\n","The running time to run each epoch: 2921.7061953544617 s\n","-------------- Epoch 4 --------------\n","44000 :  0.029378174914300323\n","46000 :  0.028620454751100827\n","48000 :  0.025971244044986325\n","50000 :  0.03316411869314203\n","52000 :  0.02684147233620784\n","54000 :  0.02631890524123787\n","56000 :  0.026534681770661202\n","Train: new_F1_Score: 0.002326325278432057 best_F1_score: 0.0038588754134509366 \n","Dev: new_F1_Score: 0.003419206508282733 best_F1_score: 0.004708375022070507 \n","Test: new_F1_Score: 0.0024148756339048543 best_F1_score: 0.0032389635316698658 \n","F1 Score of Test Set(Epoch4): 0.0024148756339048543\n","F1 Score of Development Set(Epoch4): 0.003419206508282733\n","The running time to run each epoch: 2917.4237031936646 s\n","-------------- Epoch 5 --------------\n","58000 :  0.023930629818969422\n"]}],"source":["# DONT RUN THIS CELL\n","# Move model to cuda\n","model = model.to('cuda')\n","\n","if not parameters['reload']:\n","    tr = time.time()\n","    model.train(True)\n","\n","    best_dev_F1_score = 0.0\n","\n","    # Initliase start time for execution of all the epochs\n","    start_time = time.time()\n","\n","    # Loop through the epochs\n","    for epoch in range(1,parameters['epoch']):\n","\n","        # Initliase start time for execution of per epoch\n","        start_time_per_epoch = time.time()\n","\n","        print(\"-------------- Epoch \" + str(epoch) + \" --------------\")\n","\n","        # Get data in mini-batches\n","        for i, index in enumerate(np.random.permutation(len(train_data))):\n","            count += 1\n","            data = train_data[index]\n","\n","            # Set the gradients of all model parameters to zero\n","            model.zero_grad()\n","\n","            sentence_in = data['words']\n","            sentence_in = Variable(torch.LongTensor(sentence_in))\n","            tags = data['tags']\n","            chars2 = data['chars']\n","\n","            # FOR LSTM\n","            chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n","            d = {}\n","            for i, ci in enumerate(chars2):\n","                for j, cj in enumerate(chars2_sorted):\n","                    if ci == cj and not j in d and not i in d.values():\n","                        d[j] = i\n","                        continue\n","            chars2_length = [len(c) for c in chars2_sorted]\n","            char_maxl = max(chars2_length)\n","            chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n","            for i, c in enumerate(chars2_sorted):\n","                chars2_mask[i, :chars2_length[i]] = c\n","            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n","\n","\n","            targets = torch.LongTensor(tags)\n","\n","            if use_gpu:\n","                # Get loss\n","                neg_log_likelihood = model.neg_log_likelihood(sentence_in.to('cuda'), targets.to('cuda'), chars2_mask.to('cuda'), chars2_length, d)\n","            else:\n","                # Get loss\n","                neg_log_likelihood = model.neg_log_likelihood(sentence_in, targets, chars2_mask, chars2_length, d)\n","\n","            # Get average loss\n","            loss += neg_log_likelihood.item() / len(data['words'])\n","\n","            # Perform backpropogation\n","            neg_log_likelihood.backward()\n","\n","            # Avoid exploding gradients with the use of gradient clips\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n","            optimizer.step()\n","\n","            #Storing loss\n","            if count % plot_every == 0:\n","                loss /= plot_every\n","                print(count, ': ', loss)\n","                if losses == []:\n","                    losses.append(loss)\n","                losses.append(loss)\n","                loss = 0.0\n","\n","        #Evaluating on Train, Test, Dev Sets\n","        model.train(False)\n","        best_train_F1_score, new_train_F1_score, _ = performEvaluation(model, train_data, best_train_F1_score,\"Train\")\n","        best_dev_F1_score, new_dev_F1_Score, save = performEvaluation(model, dev_data, best_dev_F1_score,\"Dev\")\n","        best_test_F1_score, new_test_F1_score, _ = performEvaluation(model, test_data, best_test_F1_score,\"Test\")\n","\n","        print(\"F1 Score of Test Set(Epoch\" + str(epoch)+ \"): \" + str(new_test_F1_score))\n","        print(\"F1 Score of Development Set(Epoch\" + str(epoch)+ \"): \" + str(new_dev_F1_Score))\n","        if save:\n","            print(\"Saving Model\")\n","            torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP_model/G38_model\")\n","\n","\n","        all_F1_Scores.append([new_train_F1_score, new_dev_F1_Score, new_test_F1_score])\n","        model.train(True)\n","\n","        print(\"The running time to run each epoch: \" + str(time.time() - start_time_per_epoch) + \" s\")\n","        adjustLearningRate(optimizer, learning_rate=learning_rate/(1+decay_rate*count/len(train_data)))\n","\n","\n","    print(\"The running time to perform training: \" + str(time.time() - start_time) + \" s\")\n","\n","    print(time.time() - tr)\n","    plt.plot(losses)\n","    plt.show()"]},{"cell_type":"markdown","source":["Due to google colab gpu limitations, each run can only execute up to a few epochs. The model is required to be reloaded multiple times to complete 10 epochs. We made multiple instances of the code to get all the desired outputs needed for the report.    "],"metadata":{"id":"XICNRkfLs0Pq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CkijiYB_skIE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e20b5ebe-f1c4-4258-f1ca-e93e6f72d457"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------- Epoch 5 --------------\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-31-9673b0c67e8a>:9: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n","  start_tags_with_padding = torch.cat([torch.cuda.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n"]},{"output_type":"stream","name":"stdout","text":["2000 :  0.07086782180622597\n","4000 :  0.08554724193884479\n","6000 :  0.0882462767384268\n","8000 :  0.07053660018359598\n","10000 :  0.07727696661831275\n","12000 :  0.060795362047532456\n","14000 :  0.05482337219255637\n","Train: new_F1_Score: 0.003120534282131296 best_F1_score: -1.0 \n","Dev: new_F1_Score: 0.004718372161604247 best_F1_score: 0.0 \n","Test: new_F1_Score: 0.003620564808110065 best_F1_score: -1.0 \n","F1 Score of Test Set(Epoch5): 0.003620564808110065\n","F1 Score of Development Set(Epoch5): 0.004718372161604247\n","Saving Model\n","The running time to run each epoch: 3036.317501783371 s\n","-------------- Epoch 6 --------------\n","16000 :  0.04672436109726962\n","18000 :  0.039822627988998396\n","20000 :  0.036865790327305095\n","22000 :  0.03808548413088015\n","24000 :  0.045280485162430585\n"]}],"source":["# DONT RUN THIS CELL\n","checkpoint = torch.load(\"/content/drive/MyDrive/NLP_model/G38_model\")\n","model.load_state_dict(checkpoint)\n","\n","\n","# Move model to cuda\n","model = model.to('cuda')\n","\n","tr = time.time()\n","model.train(True)\n","\n","best_dev_F1_score = 0.0\n","\n","# Initliase start time for execution of all the epochs\n","start_time = time.time()\n","\n","# Determine the last saved epoch\n","last_saved_epoch = 4\n","\n","# Start training from the last saved epoch + 1\n","for epoch in range(last_saved_epoch + 1, parameters['epoch']):\n","\n","# # Loop through the epochs\n","# for epoch in range(1,parameters['epoch']):\n","\n","    # Initliase start time for execution of per epoch\n","    start_time_per_epoch = time.time()\n","\n","    print(\"-------------- Epoch \" + str(epoch) + \" --------------\")\n","\n","    # Get data in mini-batches\n","    for i, index in enumerate(np.random.permutation(len(train_data))):\n","        count += 1\n","        data = train_data[index]\n","\n","        # Set the gradients of all model parameters to zero\n","        model.zero_grad()\n","\n","        sentence_in = data['words']\n","        sentence_in = Variable(torch.LongTensor(sentence_in))\n","        tags = data['tags']\n","        chars2 = data['chars']\n","\n","        # FOR LSTM\n","        chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n","        d = {}\n","        for i, ci in enumerate(chars2):\n","            for j, cj in enumerate(chars2_sorted):\n","                if ci == cj and not j in d and not i in d.values():\n","                    d[j] = i\n","                    continue\n","        chars2_length = [len(c) for c in chars2_sorted]\n","        char_maxl = max(chars2_length)\n","        chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n","        for i, c in enumerate(chars2_sorted):\n","            chars2_mask[i, :chars2_length[i]] = c\n","        chars2_mask = Variable(torch.LongTensor(chars2_mask))\n","\n","\n","        targets = torch.LongTensor(tags)\n","\n","        if use_gpu:\n","            # Get loss\n","            neg_log_likelihood = model.neg_log_likelihood(sentence_in.to('cuda'), targets.to('cuda'), chars2_mask.to('cuda'), chars2_length, d)\n","        else:\n","            # Get loss\n","            neg_log_likelihood = model.neg_log_likelihood(sentence_in, targets, chars2_mask, chars2_length, d)\n","\n","        # Get average loss\n","        loss += neg_log_likelihood.item() / len(data['words'])\n","\n","        # Perform backpropogation\n","        neg_log_likelihood.backward()\n","\n","        # Avoid exploding gradients with the use of gradient clips\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n","        optimizer.step()\n","\n","        #Storing loss\n","        if count % plot_every == 0:\n","            loss /= plot_every\n","            print(count, ': ', loss)\n","            if losses == []:\n","                losses.append(loss)\n","            losses.append(loss)\n","            loss = 0.0\n","\n","    #Evaluating on Train, Test, Dev Sets\n","    model.train(False)\n","    best_train_F1_score, new_train_F1_score, _ = performEvaluation(model, train_data, best_train_F1_score,\"Train\")\n","    best_dev_F1_score, new_dev_F1_Score, save = performEvaluation(model, dev_data, best_dev_F1_score,\"Dev\")\n","    best_test_F1_score, new_test_F1_score, _ = performEvaluation(model, test_data, best_test_F1_score,\"Test\")\n","\n","    print(\"F1 Score of Test Set(Epoch\" + str(epoch)+ \"): \" + str(new_test_F1_score))\n","    print(\"F1 Score of Development Set(Epoch\" + str(epoch)+ \"): \" + str(new_dev_F1_Score))\n","    if save:\n","        print(\"Saving Model\")\n","        torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP_model/G38_model\")\n","\n","\n","    all_F1_Scores.append([new_train_F1_score, new_dev_F1_Score, new_test_F1_score])\n","    model.train(True)\n","\n","    print(\"The running time to run each epoch: \" + str(time.time() - start_time_per_epoch) + \" s\")\n","\n","    adjustLearningRate(optimizer, learning_rate=learning_rate/(1+decay_rate*count/len(train_data)))\n","\n","\n","print(\"The running time to perform training: \" + str(time.time() - start_time) + \" s\")\n","\n","print(time.time() - tr)\n","plt.plot(losses)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mpZt05FmntM8","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0e51693d-7f79-4fe9-9b51-50a18c4e5629","executionInfo":{"status":"ok","timestamp":1699330027940,"user_tz":-480,"elapsed":11984068,"user":{"displayName":"Code200 Till","userId":"04784414087587768142"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------- Epoch 6 --------------\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-30-9673b0c67e8a>:9: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n","  start_tags_with_padding = torch.cat([torch.cuda.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n"]},{"output_type":"stream","name":"stdout","text":["2000 :  0.02285720047948826\n","4000 :  0.030650647315032014\n","6000 :  0.021808663510211913\n","8000 :  0.034182661143227794\n","10000 :  0.02546489253524515\n","12000 :  0.02881385992813444\n","14000 :  0.030312976571662237\n","Train: new_F1_Score: 0.00233730187714557 best_F1_score: -1.0 \n","Dev: new_F1_Score: 0.004267931238885595 best_F1_score: 0.0 \n","Test: new_F1_Score: 0.002432350258437215 best_F1_score: -1.0 \n","F1 Score of Test Set(Epoch6): 0.002432350258437215\n","F1 Score of Development Set(Epoch6): 0.004267931238885595\n","Saving Model\n","The running time to run each epoch: 3154.043802022934 s\n","-------------- Epoch 7 --------------\n","16000 :  0.019515358599228563\n","18000 :  0.02514976546555685\n","20000 :  0.020028070514093003\n","22000 :  0.021759246045981187\n","24000 :  0.01970245459350357\n","26000 :  0.020783244984332285\n","28000 :  0.014455211009082916\n","Train: new_F1_Score: 0.0021224940759155078 best_F1_score: 0.00233730187714557 \n","Dev: new_F1_Score: 0.00319337670017741 best_F1_score: 0.004267931238885595 \n","Test: new_F1_Score: 0.0023010778733196075 best_F1_score: 0.002432350258437215 \n","F1 Score of Test Set(Epoch7): 0.0023010778733196075\n","F1 Score of Development Set(Epoch7): 0.00319337670017741\n","The running time to run each epoch: 2912.550426721573 s\n","-------------- Epoch 8 --------------\n","30000 :  0.016100294631066044\n","32000 :  0.014553410543503984\n","34000 :  0.01424637520386563\n","36000 :  0.01613811069999507\n","38000 :  0.010956559274768471\n","40000 :  0.019878571059055865\n","42000 :  0.019007541300062505\n","Train: new_F1_Score: 0.0023419880876655295 best_F1_score: 0.00233730187714557 \n","Dev: new_F1_Score: 0.003376804843968328 best_F1_score: 0.004267931238885595 \n","Test: new_F1_Score: 0.0028469750889679713 best_F1_score: 0.002432350258437215 \n","F1 Score of Test Set(Epoch8): 0.0028469750889679713\n","F1 Score of Development Set(Epoch8): 0.003376804843968328\n","The running time to run each epoch: 2909.1956672668457 s\n","-------------- Epoch 9 --------------\n","44000 :  0.013241294037032468\n","46000 :  0.009754542931285706\n","48000 :  0.010686486612412626\n","50000 :  0.016412198414456555\n","52000 :  0.013450998163356355\n","54000 :  0.01717139370648988\n","56000 :  0.013170531287194255\n","Train: new_F1_Score: 0.002235707441711913 best_F1_score: 0.0023419880876655295 \n","Dev: new_F1_Score: 0.003173110823833588 best_F1_score: 0.004267931238885595 \n","Test: new_F1_Score: 0.002287778446718844 best_F1_score: 0.0028469750889679713 \n","F1 Score of Test Set(Epoch9): 0.002287778446718844\n","F1 Score of Development Set(Epoch9): 0.003173110823833588\n","The running time to run each epoch: 2908.2078976631165 s\n","The running time to perform training: 11883.999492645264 s\n","11884.001761436462\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 512x384 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# DONT RUN THIS CELL\n","checkpoint = torch.load(\"/content/drive/MyDrive/NLP_model/G38_model\")\n","model.load_state_dict(checkpoint)\n","\n","\n","# Move model to cuda\n","model = model.to('cuda')\n","\n","tr = time.time()\n","model.train(True)\n","\n","best_dev_F1_score = 0.0\n","\n","# Initliase start time for execution of all the epochs\n","start_time = time.time()\n","\n","# Determine the last saved epoch\n","last_saved_epoch = 5\n","\n","# Start training from the last saved epoch + 1\n","for epoch in range(last_saved_epoch + 1, parameters['epoch']):\n","\n","# # Loop through the epochs\n","# for epoch in range(1,parameters['epoch']):\n","\n","    # Initliase start time for execution of per epoch\n","    start_time_per_epoch = time.time()\n","\n","    print(\"-------------- Epoch \" + str(epoch) + \" --------------\")\n","\n","    # Get data in mini-batches\n","    for i, index in enumerate(np.random.permutation(len(train_data))):\n","        count += 1\n","        data = train_data[index]\n","\n","        # Set the gradients of all model parameters to zero\n","        model.zero_grad()\n","\n","        sentence_in = data['words']\n","        sentence_in = Variable(torch.LongTensor(sentence_in))\n","        tags = data['tags']\n","        chars2 = data['chars']\n","\n","        # FOR LSTM\n","        chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n","        d = {}\n","        for i, ci in enumerate(chars2):\n","            for j, cj in enumerate(chars2_sorted):\n","                if ci == cj and not j in d and not i in d.values():\n","                    d[j] = i\n","                    continue\n","        chars2_length = [len(c) for c in chars2_sorted]\n","        char_maxl = max(chars2_length)\n","        chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n","        for i, c in enumerate(chars2_sorted):\n","            chars2_mask[i, :chars2_length[i]] = c\n","        chars2_mask = Variable(torch.LongTensor(chars2_mask))\n","\n","\n","        targets = torch.LongTensor(tags)\n","\n","        if use_gpu:\n","            # Get loss\n","            neg_log_likelihood = model.neg_log_likelihood(sentence_in.to('cuda'), targets.to('cuda'), chars2_mask.to('cuda'), chars2_length, d)\n","        else:\n","            # Get loss\n","            neg_log_likelihood = model.neg_log_likelihood(sentence_in, targets, chars2_mask, chars2_length, d)\n","\n","        # Get average loss\n","        loss += neg_log_likelihood.item() / len(data['words'])\n","\n","        # Perform backpropogation\n","        neg_log_likelihood.backward()\n","\n","        # Avoid exploding gradients with the use of gradient clips\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n","        optimizer.step()\n","\n","        #Storing loss\n","        if count % plot_every == 0:\n","            loss /= plot_every\n","            print(count, ': ', loss)\n","            if losses == []:\n","                losses.append(loss)\n","            losses.append(loss)\n","            loss = 0.0\n","\n","    #Evaluating on Train, Test, Dev Sets\n","    model.train(False)\n","    best_train_F1_score, new_train_F1_score, _ = performEvaluation(model, train_data, best_train_F1_score,\"Train\")\n","    best_dev_F1_score, new_dev_F1_Score, save = performEvaluation(model, dev_data, best_dev_F1_score,\"Dev\")\n","    best_test_F1_score, new_test_F1_score, _ = performEvaluation(model, test_data, best_test_F1_score,\"Test\")\n","\n","    print(\"F1 Score of Test Set(Epoch\" + str(epoch)+ \"): \" + str(new_test_F1_score))\n","    print(\"F1 Score of Development Set(Epoch\" + str(epoch)+ \"): \" + str(new_dev_F1_Score))\n","    if save:\n","        print(\"Saving Model\")\n","        torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP_model/G38_model\")\n","\n","\n","    all_F1_Scores.append([new_train_F1_score, new_dev_F1_Score, new_test_F1_score])\n","    model.train(True)\n","\n","    print(\"The running time to run each epoch: \" + str(time.time() - start_time_per_epoch) + \" s\")\n","\n","    adjustLearningRate(optimizer, learning_rate=learning_rate/(1+decay_rate*count/len(train_data)))\n","\n","\n","print(\"The running time to perform training: \" + str(time.time() - start_time) + \" s\")\n","\n","print(time.time() - tr)\n","plt.plot(losses)\n","plt.show()"]},{"cell_type":"code","source":["checkpoint = torch.load(\"/content/drive/MyDrive/NLP_model/G38_model\")\n","model.load_state_dict(checkpoint)\n","\n","\n","# Move model to cuda\n","model = model.to('cuda')\n","\n","tr = time.time()\n","model.train(True)\n","\n","best_dev_F1_score = 0.0\n","\n","# Initliase start time for execution of all the epochs\n","start_time = time.time()\n","\n","# Determine the last saved epoch\n","# last_saved_epoch = 9\n","epoch = parameters['epoch']\n","\n","# Initliase start time\n","start_time_per_epoch = time.time()\n","\n","print(\"-------------- Epoch \" + str(epoch) + \" --------------\")\n","\n","# Get data in mini-batches\n","for i, index in enumerate(np.random.permutation(len(train_data))):\n","    count += 1\n","    data = train_data[index]\n","\n","    # Set the gradients of all model parameters to zero\n","    model.zero_grad()\n","\n","    sentence_in = data['words']\n","    sentence_in = Variable(torch.LongTensor(sentence_in))\n","    tags = data['tags']\n","    chars2 = data['chars']\n","\n","    # FOR LSTM\n","    chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n","    d = {}\n","    for i, ci in enumerate(chars2):\n","        for j, cj in enumerate(chars2_sorted):\n","            if ci == cj and not j in d and not i in d.values():\n","                d[j] = i\n","                continue\n","    chars2_length = [len(c) for c in chars2_sorted]\n","    char_maxl = max(chars2_length)\n","    chars2_mask = np.zeros((len(chars2_sorted), char_maxl), dtype='int')\n","    for i, c in enumerate(chars2_sorted):\n","        chars2_mask[i, :chars2_length[i]] = c\n","    chars2_mask = Variable(torch.LongTensor(chars2_mask))\n","\n","\n","    targets = torch.LongTensor(tags)\n","\n","    if use_gpu:\n","        # Get loss\n","        neg_log_likelihood = model.neg_log_likelihood(sentence_in.to('cuda'), targets.to('cuda'), chars2_mask.to('cuda'), chars2_length, d)\n","    else:\n","        # Get loss\n","        neg_log_likelihood = model.neg_log_likelihood(sentence_in, targets, chars2_mask, chars2_length, d)\n","\n","    # Get average loss\n","    loss += neg_log_likelihood.item() / len(data['words'])\n","\n","    # Perform backpropogation\n","    neg_log_likelihood.backward()\n","\n","    # Avoid exploding gradients with the use of gradient clips\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n","    optimizer.step()\n","\n","    #Storing loss\n","    if count % plot_every == 0:\n","        loss /= plot_every\n","        print(count, ': ', loss)\n","        if losses == []:\n","            losses.append(loss)\n","        losses.append(loss)\n","        loss = 0.0\n","\n","#Evaluating on Train, Test, Dev Sets\n","model.train(False)\n","best_train_F1_score, new_train_F1_score, _ = performEvaluation(model, train_data, best_train_F1_score,\"Train\")\n","best_dev_F1_score, new_dev_F1_Score, save = performEvaluation(model, dev_data, best_dev_F1_score,\"Dev\")\n","best_test_F1_score, new_test_F1_score, _ = performEvaluation(model, test_data, best_test_F1_score,\"Test\")\n","\n","print(\"F1 Score of Test Set(Epoch\" + str(epoch)+ \"): \" + str(new_test_F1_score))\n","print(\"F1 Score of Development Set(Epoch\" + str(epoch)+ \"): \" + str(new_dev_F1_Score))\n","if save:\n","    print(\"Saving Model\")\n","    torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP_model/G38_model\")\n","\n","\n","all_F1_Scores.append([new_train_F1_score, new_dev_F1_Score, new_test_F1_score])\n","model.train(True)\n","\n","print(\"The running time to run each epoch: \" + str(time.time() - start_time_per_epoch) + \" s\")\n","\n","adjustLearningRate(optimizer, learning_rate=learning_rate/(1+decay_rate*count/len(train_data)))\n","\n","\n","print(\"The running time to perform training: \" + str(time.time() - start_time) + \" s\")\n","\n","print(time.time() - tr)\n","plt.plot(losses)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":696},"id":"dwniqb5aJjOF","executionInfo":{"status":"ok","timestamp":1699337160929,"user_tz":-480,"elapsed":3074019,"user":{"displayName":"Code Till","userId":"00349487664103867259"}},"outputId":"d6546f74-edc8-489f-ad7b-e86901fd512e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-------------- Epoch 10 --------------\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-30-9673b0c67e8a>:9: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n","  start_tags_with_padding = torch.cat([torch.cuda.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n"]},{"output_type":"stream","name":"stdout","text":["2000 :  0.017801072055355385\n","4000 :  0.02309376797811614\n","6000 :  0.016408120106657473\n","8000 :  0.024127455268095822\n","10000 :  0.01920241689763682\n","12000 :  0.022950091924196146\n","14000 :  0.022940817097537113\n","Train: new_F1_Score: 0.002418062636562273 best_F1_score: -1.0 \n","Dev: new_F1_Score: 0.003929507025482257 best_F1_score: 0.0 \n","Test: new_F1_Score: 0.002190847127555988 best_F1_score: -1.0 \n","F1 Score of Test Set(Epoch10): 0.002190847127555988\n","F1 Score of Development Set(Epoch10): 0.003929507025482257\n","Saving Model\n","The running time to run each epoch: 2965.505757331848 s\n","The running time to perform training: 2965.5204224586487 s\n","2965.5234026908875\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 512x384 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# timing from epoch 1 + 2 + 3 + 4 + 5 + [6-9] + 10\n","time_for_all_epoch = 3289.4680638313293 + 2918.7407414913177 + 2921.7061953544617 + 2917.4237031936646 + 3036.317501783371 + 11883.999492645264 + 2965.5204224586487\n","print (\"Total running time:\")\n","print(str(time_for_all_epoch) + \"s\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gc2XiiLtLw8N","executionInfo":{"status":"ok","timestamp":1699502217958,"user_tz":-480,"elapsed":324,"user":{"displayName":"Yong, Nigel Tan","userId":"16529283802002184974"}},"outputId":"503a02ec-97e8-439c-f921-dcf708cf79b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total running time:\n","29933.176120758057s\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4OG2UqFrOGu3"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}